{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Gradient base methods*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "from numpy import array,dot\n",
    "\n",
    "def sum_of_squares(v: array) -> float:\n",
    "    return dot(v,v)\n",
    "\n",
    "def partial_difference_quotient(f: Callable[[array,array,array],float], \n",
    "                                A:array, X:array, B: array, i: int, h: float) -> float:\n",
    "    w = [v_j + (h if j==i else 0) for j, v_j in enumerate(X)]\n",
    "    return (f(A,w,B)-f(A,X,B)) / h\n",
    "\n",
    "def estimate_gradient(f: Callable[[array,array,array],float], A: array, X:array, B: array, h: float):\n",
    "    return np.array([partial_difference_quotient(f,A,X,B,i,h) for i in range(len(X))])\n",
    "\n",
    "def calculateLoss(A: array, X: array, B: array) -> float:\n",
    "    linear_comb = [dot(a,X) for a in A]\n",
    "    loss_vector = B - linear_comb\n",
    "    squared_error = [i ** 2 for i in loss_vector]\n",
    "    total_loss = sum(squared_error) / (2 * len(A))\n",
    "    return total_loss\n",
    "\n",
    "def gradient_step(gradient: array, step_size:float) -> array:    \n",
    "    return np.multiply(gradient,step_size)    \n",
    "\n",
    "def vectorNorm(v: array) -> float:\n",
    "    return sqrt(dot(v,v))\n",
    "\n",
    "def matrixTimesVector(A: array,V: array) -> array:\n",
    "    assert len(A[0]) == len(V)\n",
    "    return [dot(a,V) for a in A]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Gradient Algorithm*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeGradient(A: array, X: array, B: array, useMomentum = True):\n",
    "\n",
    "    near_zero = 0.0001\n",
    "    learning_rate = -0.1\n",
    "    momentum = 0.1\n",
    "    past_velocity = 0.\n",
    "    velocity = 0.\n",
    "    tolerance = near_zero\n",
    "    iter = 0\n",
    "\n",
    "    for iter in range(1000):\n",
    "        grad = estimate_gradient(calculateLoss, A, X, B, near_zero)\n",
    "        assert len(X) == len(grad)\n",
    "        step = gradient_step(grad, learning_rate) \n",
    "        if(useMomentum):       \n",
    "            velocity = past_velocity * momentum - step        \n",
    "            X = X + (momentum * velocity) + step\n",
    "        else:\n",
    "            X = X + step\n",
    "        past_velocity = velocity\n",
    "        grad_norm = vectorNorm(grad)        \n",
    "        if grad_norm < tolerance:\n",
    "            break\n",
    "\n",
    "    print(\"B = \", B)\n",
    "    print(\"X: \", X)\n",
    "    print(\"A*x = \", matrixTimesVector(A, X))\n",
    "    print(\"Gradient: \", (grad * learning_rate))\n",
    "    print(\"Number of Iterations: \", iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Aux methods for generating specific matrices:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillMatrixExercise11(matriz: array, vetorB:array,n:int):\n",
    "   assert (n % 2 != 0), \"N must be an odd number.\"\n",
    "  \n",
    "   for i in range(n):\n",
    "      if i == 0 or i == (n-1):\n",
    "         vetorB[i] = 2.5      \n",
    "      elif i == n - i - 1:\n",
    "         vetorB[i] = 1.0      \n",
    "      else:\n",
    "         vetorB[i] = 1.5      \n",
    "      \n",
    "      matriz[i][i] = 3.0\n",
    "      \n",
    "      if i != n - i - 1:\n",
    "         matriz[i][n - i - 1] = 0.5\n",
    "      if i > 0:\n",
    "         matriz[i][i - 1] = -1.0\n",
    "      if i < n - 1:\n",
    "         matriz[i][i + 1] = -1.0   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Symetric matrix linear equation example:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  -1.   0.   0.   0.   0.   0.   0.   0.   0.   0.5]\n",
      " [-1.   3.  -1.   0.   0.   0.   0.   0.   0.   0.5  0. ]\n",
      " [ 0.  -1.   3.  -1.   0.   0.   0.   0.   0.5  0.   0. ]\n",
      " [ 0.   0.  -1.   3.  -1.   0.   0.   0.5  0.   0.   0. ]\n",
      " [ 0.   0.   0.  -1.   3.  -1.   0.5  0.   0.   0.   0. ]\n",
      " [ 0.   0.   0.   0.  -1.   3.  -1.   0.   0.   0.   0. ]\n",
      " [ 0.   0.   0.   0.   0.5 -1.   3.  -1.   0.   0.   0. ]\n",
      " [ 0.   0.   0.   0.5  0.   0.  -1.   3.  -1.   0.   0. ]\n",
      " [ 0.   0.   0.5  0.   0.   0.   0.  -1.   3.  -1.   0. ]\n",
      " [ 0.   0.5  0.   0.   0.   0.   0.   0.  -1.   3.  -1. ]\n",
      " [ 0.5  0.   0.   0.   0.   0.   0.   0.   0.  -1.   3. ]]\n",
      "[2.5 1.5 1.5 1.5 1.5 1.  1.5 1.5 1.5 1.5 2.5]\n",
      "B =  [2.5 1.5 1.5 1.5 1.5 1.  1.5 1.5 1.5 1.5 2.5]\n",
      "X:  [0.99983883 0.99972937 0.99965342 0.99958605 0.99950621 0.99938917\n",
      " 0.99950621 0.99958605 0.99965342 0.99972937 0.99983883]\n",
      "A*x =  [2.499706524291554, 1.4995605321261798, 1.4994715639570804, 1.499391540102351, 1.499296507702145, 0.9991550987139315, 1.4992965077021632, 1.4993915401023838, 1.4994715639571174, 1.4995605321262127, 2.499706524291573]\n",
      "Gradient:  [6.95519697e-07 1.42184545e-06 2.21145852e-06 3.10012236e-06\n",
      " 4.12842243e-06 5.34334534e-06 4.12842243e-06 3.10012236e-06\n",
      " 2.21145852e-06 1.42184545e-06 6.95519696e-07]\n",
      "Number of Iterations:  501\n"
     ]
    }
   ],
   "source": [
    "n = 11\n",
    "A = np.zeros((n,n))\n",
    "B = np.zeros(n)\n",
    "X = np.zeros(n)\n",
    "\n",
    "fillMatrixExercise11(A,B,n)\n",
    "\n",
    "print(A)\n",
    "print(B)\n",
    "\n",
    "computeGradient(A,X,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Simple Linear equation example:*\n",
    "A . X = B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B =  [7. 5. 3.]\n",
      "X:  [4.19289064 3.2328617  2.08083308]\n",
      "A*x =  [6.999756157093863, 4.999772899355044, 2.9998018570798832]\n",
      "Gradient:  [6.31193449e-06 5.68619958e-06 4.45139488e-06]\n",
      "Number of Iterations:  123\n"
     ]
    }
   ],
   "source": [
    "A = array([[2.0, -0.3, -0.2], \n",
    "    [-0.3, 2.0, -0.1], \n",
    "    [-0.2, -0.1, 2.0]])\n",
    "\n",
    "B = array([7.0, 5.0, 3.0])\n",
    "\n",
    "X = array([0,0,0])\n",
    "\n",
    "computeGradient(A,X,B, False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50fe882ca904cb0bee4830053affed36ca26250fa3534c4aafa37ae55e877e0e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
